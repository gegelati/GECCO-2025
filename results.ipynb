{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GECCO 2025\n",
    "# MAPLE: Multi-Action Program through Linear Evolution for Continuous Multi-Action Reinforcement Learning\n",
    "## Quentin Vacher, Stephen Kelly, Ali Naqvi, Nicolas Beuve, Tanya Djavaherpour, Mickaël Dardaillon and Karols Desnos\n",
    "\n",
    "This notebook uses the experiment results of the MAPLE algorithm to create and export the figures and data proposed in the MAPLE paper cited above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportation of libraries and utils code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_format(ax1=None):\n",
    "    if(ax1 != None):\n",
    "        ax = ax1\n",
    "    else:\n",
    "        ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "# Permet d'afficher plus de colonnes sans revenir à la ligne\n",
    "pd.set_option('display.max_columns', None)  # Afficher toutes les colonnes\n",
    "pd.set_option('display.width', None)        # Permet de s'ajuster à la largeur de l'écran\n",
    "pd.set_option('display.max_rows', None)     # Option pour afficher toutes les lignes si nécessaire\n",
    "\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "l_colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data of MAPLE, MATPG and TPG.\n",
    "\n",
    "This three algorithms were used with the Gegelati library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbSeed = 10\n",
    "\n",
    "allEnvironments = [\n",
    "    \"inverted_double_pendulum\",\n",
    "    \"hopper\",\n",
    "    \"half_cheetah\",\n",
    "    \"walker2d\",\n",
    "    \"ant\",\n",
    "    \"humanoid\"\n",
    "]\n",
    "\n",
    "algo = [\n",
    "    \"MAPLE\",\n",
    "    \"MATPG\",\n",
    "    \"TPG\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for a in algo:\n",
    "    for e in allEnvironments:\n",
    "        for i in range(nbSeed):\n",
    "            key = f\"logs/{a}/{e}/out.{i}.p0.{e}.std\"\n",
    "            try:\n",
    "                df = pd.read_csv(key, sep=r'\\s+', skiprows=1)\n",
    "                df = df.dropna()\n",
    "                for col in df.columns:\n",
    "                    if \"U_Min\" == col:\n",
    "                        df = df.rename(columns={col: \"MinTraining\"})\n",
    "                    if \"U_Avg\" == col:\n",
    "                        df = df.rename(columns={col: \"AvgTraining\"})\n",
    "                    if \"U_Max\" == col:\n",
    "                        df = df.rename(columns={col: \"MaxTraining\"})\n",
    "\n",
    "                    if \"U_Min.1\" == col:\n",
    "                        df = df.rename(columns={col: \"MinValidation\"})\n",
    "                    if \"U_Avg.1\" == col:\n",
    "                        df = df.rename(columns={col: \"AvgValidation\"})\n",
    "                    if \"U_Max.1\" == col:\n",
    "                        df = df.rename(columns={col: \"MaxValidation\"})\n",
    "\n",
    "                    if \"R_Min\" == col:\n",
    "                        df = df.rename(columns={col: \"MinTrainingScore\"})\n",
    "                    if \"R_Avg\" == col:\n",
    "                        df = df.rename(columns={col: \"AvgTrainingScore\"})\n",
    "                    if \"R_Max\" == col:\n",
    "                        df = df.rename(columns={col: \"MaxTrainingScore\"})\n",
    "\n",
    "                    if \"R_Min.1\" == col:\n",
    "                        df = df.rename(columns={col: \"MinValidationScore\"})\n",
    "                    if \"R_Avg.1\" == col:\n",
    "                        df = df.rename(columns={col: \"AvgValidationScore\"})\n",
    "                    if \"R_Max.1\" == col:\n",
    "                        df = df.rename(columns={col: \"MaxValidationScore\"})\n",
    "\n",
    "                    if \"Min\" == col:\n",
    "                        df = df.rename(columns={col: \"MinTraining\"})\n",
    "                    if \"Avg\" == col:\n",
    "                        df = df.rename(columns={col: \"AvgTraining\"})\n",
    "                    if \"Max\" == col:\n",
    "                        df = df.rename(columns={col: \"MaxTraining\"})\n",
    "\n",
    "                    if \"Min.1\" == col:\n",
    "                        df = df.rename(columns={col: \"MinValidation\"})\n",
    "                    if \"Avg.1\" == col:\n",
    "                        df = df.rename(columns={col: \"AvgValidation\"})\n",
    "                    if \"Max.1\" == col:\n",
    "                        df = df.rename(columns={col: \"MaxValidation\"})\n",
    "                    \n",
    "\n",
    "                # Add algorithm, environment, and seed columns\n",
    "                df['algorithm'] = a\n",
    "                df['environment'] = e\n",
    "                df['seed'] = i\n",
    "                all_data.append(df)\n",
    "            except Exception as ex:\n",
    "                print(f\"Error reading {key}\", end=\"\\r\")\n",
    "print(len(all_data))\n",
    "\n",
    "# Concatenate all into a single DataFrame\n",
    "df = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw results of MAPLE, MATPG and TPG on the MuJoCo suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour obtenir la dernière génération de chaque seed\n",
    "def get_last_generation(group):\n",
    "    return group[group['Gen'] == group['Gen'].max()]\n",
    "\n",
    "# Appliquer la fonction pour obtenir les dernières générations\n",
    "last_generations = df.groupby(['algorithm', 'environment', 'seed']).apply(get_last_generation).reset_index(drop=True)\n",
    "\n",
    "# Calculer la moyenne, l'écart-type et la médiane des valeurs dans la colonne MaxValidation pour chaque couple environnement/algo\n",
    "results = last_generations.groupby(['algorithm', 'environment'])['MaxValidation'].agg(['mean', 'std', 'median']).reset_index()\n",
    "\n",
    "# Renommer les colonnes pour plus de clarté\n",
    "results = results.rename(columns={'mean': 'Mean', 'std': 'Standard Deviation', 'median': 'Median'})\n",
    "\n",
    "# Afficher les résultats\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beautifulEnvName = {\n",
    "    \"inverted_double_pendulum\": \"Inverted Double Pendulum\",\n",
    "    \"hopper\": \"Hopper\",\n",
    "    \"half_cheetah\": \"Half Cheetah\",\n",
    "    \"walker2d\": \"Walker 2D\",\n",
    "    \"ant\": \"Ant\",\n",
    "    \"humanoid\": \"Humanoid\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of the training curves of MAPLE, MATPG and TPG on each MuJoCo environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal = 'Gen'\n",
    "yVal = 'MaxValidation'\n",
    "\n",
    "# Calculer la moyenne des seeds pour chaque combinaison d'environnement, d'algorithme et de génération\n",
    "average_df = df.groupby(['environment', 'algorithm', xVal])[yVal].agg(['mean', 'std', 'median']).reset_index()\n",
    "\n",
    "max_wanted = True\n",
    "func1, func2, text = (np.amax, np.argmax, \"Max\") if max_wanted else (np.amin, np.argmin, \"Min\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # 2 lignes, 3 colonnes\n",
    "\n",
    "\n",
    "# Créer un graphique pour chaque environnement\n",
    "for i, (env, ax) in enumerate(zip(allEnvironments, axs.flat)):\n",
    "    ax.set_title(beautifulEnvName[env])\n",
    "    indexColor = 0\n",
    "\n",
    "    # Tracer l'évolution de la moyenne de MaxValidation pour chaque algorithme\n",
    "    for algo in average_df['algorithm'].unique():\n",
    "        subset = average_df[(average_df['environment'] == env) & (average_df['algorithm'] == algo)]\n",
    "        if not subset.empty:\n",
    "            ax.plot(subset[xVal], subset['mean'], label=algo, color=l_colors[indexColor])\n",
    "            ax.fill_between(subset[xVal], subset['mean'] - subset['std'], subset['mean'] + subset['std'], color=l_colors[indexColor], alpha=0.2)\n",
    "            indexColor+=1\n",
    "\n",
    "    classic_format(ax)\n",
    "\n",
    "    # Format classique pour chaque subplot\n",
    "    colorAxe = \"#051937\"\n",
    "    ax.spines['bottom'].set_color(colorAxe)  # Couleur de l'axe x\n",
    "    ax.spines['left'].set_color(colorAxe)\n",
    "\n",
    "    ax.set_xlabel(\"Generations\", fontsize=12, color=colorAxe)\n",
    "    ax.set_ylabel(\"Score\", fontsize=12, color=colorAxe)\n",
    "    ax.tick_params(axis='x', labelsize=10, colors=colorAxe)\n",
    "    ax.tick_params(axis='y', labelsize=10, colors=colorAxe)\n",
    "    ax.legend(fontsize=8, labelcolor=colorAxe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critères d’axes\n",
    "xVal = 'Gen'\n",
    "yVal = 'MaxValidation'\n",
    "max_wanted = True\n",
    "func1, func2, text = (np.amax, np.argmax, \"Max\") if max_wanted else (np.amin, np.argmin, \"Min\")\n",
    "\n",
    "# Parcourir chaque environnement\n",
    "for indexEnv, env in enumerate(allEnvironments):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    ax = plt.gca()\n",
    "    indexColor = 0\n",
    "\n",
    "    # Parcourir les algorithmes\n",
    "    for algo in average_df['algorithm'].unique():\n",
    "        subset = average_df[(average_df['environment'] == env) & (average_df['algorithm'] == algo)]\n",
    "        if not subset.empty:\n",
    "            x = subset[xVal]\n",
    "            y_mean = subset['mean']\n",
    "            y_std = subset['std']\n",
    "\n",
    "            plt.plot(x, y_mean, label=algo, color=l_colors[indexColor], alpha=0.8)\n",
    "            plt.fill_between(x, y_mean - y_std, y_mean + y_std, color=l_colors[indexColor], alpha=0.2)\n",
    "\n",
    "\n",
    "            indexColor += 1\n",
    "\n",
    "    classic_format()\n",
    "    \n",
    "    colorAxe = \"black\"\n",
    "    ax.spines['bottom'].set_color(colorAxe)\n",
    "    ax.spines['left'].set_color(colorAxe)\n",
    "\n",
    "    if indexEnv > 2:\n",
    "        plt.xlabel(\"Generations\", fontsize=32, color=colorAxe)\n",
    "    else:\n",
    "        plt.xlabel(\"\", fontsize=1, color=colorAxe)\n",
    "\n",
    "    if indexEnv % 3 == 0:\n",
    "        plt.ylabel(\"Score\", fontsize=32, color=colorAxe)\n",
    "    else:\n",
    "        plt.ylabel(\"\", fontsize=1, color=colorAxe)\n",
    "\n",
    "    if indexEnv == 5:\n",
    "        plt.legend(fontsize=24, labelcolor=colorAxe)\n",
    "\n",
    "    plt.tick_params(axis='x', labelsize=24, colors=colorAxe)\n",
    "    plt.tick_params(axis='y', labelsize=24, colors=colorAxe)\n",
    "    plt.title(beautifulEnvName[env], fontsize=32, color=colorAxe)\n",
    "\n",
    "    plt.savefig(f'exported_results/scoreMAPLE_{env}.pdf', format=\"pdf\", dpi=100, transparent=True, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data of PPO and SAC, and then LGP on the MuJoCo tasks\n",
    "\n",
    "The PPO and SAC results were optained with stable baseline 3\n",
    "\n",
    "The LGP results are directly imported from **Giorgia Nadizar, Eric Medvet, and Dennis G Wilson. 2024. Naturally Interpretable\n",
    "Control Policies via Graph-Based Genetic Programming. In European Conference\n",
    "on Genetic Programming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaires pour stocker les données par algorithme\n",
    "data_PPO = {\n",
    "    \"inverted_double_pendulum\": [],\n",
    "    \"hopper\": [],\n",
    "    \"half_cheetah\": [],\n",
    "    \"walker2d\": [],\n",
    "    \"ant\": [],\n",
    "    \"humanoid\": [],\n",
    "}\n",
    "data_SAC = {\n",
    "    \"inverted_double_pendulum\": [],\n",
    "    \"hopper\": [],\n",
    "    \"half_cheetah\": [],\n",
    "    \"walker2d\": [],\n",
    "    \"ant\": [],\n",
    "    \"humanoid\": [],\n",
    "}\n",
    "\n",
    "# Mapping pour convertir le nom de l'environnement en clé du dictionnaire\n",
    "env_key_mapping = {\n",
    "    \"InvertedDoublePendulum-v4\": \"inverted_double_pendulum\",\n",
    "    \"Hopper-v4\": \"hopper\",\n",
    "    \"HalfCheetah-v4\": \"half_cheetah\",\n",
    "    \"Walker2d-v4\": \"walker2d\",\n",
    "    \"Ant-v4\": \"ant\",\n",
    "    \"Humanoid-v4\": \"humanoid\",\n",
    "}\n",
    "\n",
    "# Lecture des données depuis le fichier CSV\n",
    "csv_file = \"sumup_rl_results.csv\"\n",
    "\n",
    "with open(csv_file, mode='r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        env_name = env_key_mapping.get(row[\"Env_Name\"], None)\n",
    "        algorithm = row[\"Algorithm\"].lower()\n",
    "        average_reward = float(row[\"Average_Reward\"])\n",
    "\n",
    "        # Ajouter la récompense au bon algorithme et environnement\n",
    "        if env_name:\n",
    "            if algorithm == \"ppo\":\n",
    "                data_PPO[env_name].append(average_reward)\n",
    "            elif algorithm == \"sac\":\n",
    "                data_SAC[env_name].append(average_reward)\n",
    "\n",
    "# Affichage des données mises à jour\n",
    "print(\"Data PPO:\", data_PPO)\n",
    "print(\"Data SAC:\", data_SAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from Nadizar paper on LGP.\n",
    "data_LGP = {\n",
    "    \"half_cheetah\": [6401.04345703125, 6532.55078125, 6097.98388671875, 6575.6025390625, 6169.09765625, 6727.05322265625, 6567.09912109375, 6931.47802734375, 6373.47021484375, 4681.67431640625],\n",
    "    \"hopper\": [1087.8963623046875, 1348.1890869140625, 1126.781494140625, 1263.3856201171875, 1141.8143310546875, 1338.2640380859375, 1123.2767333984375, 1047.4007568359375, 1118.4427490234375, 1080.1868896484375],\n",
    "    \"inverted_double_pendulum\": [9455.7724609375, 9484.845703125, 9412.7041015625, 9472.5517578125, 9341.8974609375, 9286.3720703125, 9421.6337890625, 9438.5732421875, 9363.98828125, 9496.0537109375],\n",
    "    \"ant\": [1023.5964965820312, 1626.9891357421875, 1211.2357177734375, 1219.8675537109375, 1490.741943359375, 1217.9986572265625, 1217.7010498046875, 1034.7437744140625, 1409.8453369140625, 1491.4927978515625],\n",
    "    \"walker2d\": [1133.5540771484375, 1121.1778564453125, 1136.4681396484375, 979.43212890625, 1142.1771240234375, 1122.7728271484375, 1193.9232177734375, 982.2586059570312, 1125.2513427734375, 1146.8472900390625],\n",
    "    \"humanoid\": [np.nan]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que la colonne MaxValidation est bien numérique\n",
    "df['MaxValidation'] = pd.to_numeric(df['MaxValidation'], errors='coerce')\n",
    "\n",
    "# Supprimer les NaN potentiels\n",
    "df = df.dropna(subset=['MaxValidation'])\n",
    "\n",
    "# Obtenir la dernière ligne pour chaque seed/env/algo\n",
    "last_values_df = df.sort_values('Gen').groupby(['algorithm', 'environment', 'seed']).tail(1)\n",
    "\n",
    "# Garder uniquement les colonnes utiles (vous pouvez en ajouter d'autres si besoin)\n",
    "df_All_Score = last_values_df[['algorithm', 'environment', 'seed', 'MaxValidation']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour convertir les dictionnaires en DataFrame\n",
    "def convert_dict_to_df(data_dict, algo_name):\n",
    "    records = []\n",
    "    for env, rewards in data_dict.items():\n",
    "        for seed, reward in enumerate(rewards):\n",
    "            records.append({\n",
    "                \"algorithm\": algo_name,\n",
    "                \"environment\": env,\n",
    "                \"seed\": seed,\n",
    "                \"MaxValidation\": reward  # Tu peux changer le nom ici si besoin\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Convertir PPO et SAC en DataFrame\n",
    "ppo_df = convert_dict_to_df(data_PPO, \"PPO\")\n",
    "sac_df = convert_dict_to_df(data_SAC, \"SAC\")\n",
    "\n",
    "# Concaténer avec le DataFrame existant\n",
    "df_All_Score = pd.concat([df_All_Score, ppo_df, sac_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir le dictionnaire LGP en DataFrame\n",
    "def convert_lgp_to_df(data_dict):\n",
    "    records = []\n",
    "    for env, rewards in data_dict.items():\n",
    "        for seed, reward in enumerate(rewards):\n",
    "            records.append({\n",
    "                \"algorithm\": \"LGP\",\n",
    "                \"environment\": env,\n",
    "                \"seed\": seed,\n",
    "                \"MaxValidation\": reward\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Conversion\n",
    "lgp_df = convert_lgp_to_df(data_LGP)\n",
    "\n",
    "# Concaténation\n",
    "df_All_Score = pd.concat([df_All_Score, lgp_df], ignore_index=True)\n",
    "\n",
    "# Afficher un aperçu\n",
    "df_All_Score.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing boxplot of each algorithm on each of the MuJoCo environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environnements et labels\n",
    "envs = [\"inverted_double_pendulum\", \"hopper\", \"half_cheetah\", \"walker2d\", \"ant\", \"humanoid\"]\n",
    "labels = [\"LGP\", \"MAPLE\", \"TPG\", \"MATPG\", \"PPO\", \"SAC\"]\n",
    "grouped_labels = [\"LGP\", \"TPG\", \"DRL\"]\n",
    "\n",
    "# Mapping noms jolis\n",
    "beautifulEnvName = {\n",
    "    \"inverted_double_pendulum\": \"Inverted Double Pendulum\",\n",
    "    \"hopper\": \"Hopper\",\n",
    "    \"half_cheetah\": \"Half-Cheetah\",\n",
    "    \"walker2d\": \"Walker2D\",\n",
    "    \"ant\": \"Ant\",\n",
    "    \"humanoid\": \"Humanoid\"\n",
    "}\n",
    "\n",
    "# Couleurs\n",
    "colors = {\n",
    "    \"LGP\": \"#1f77b4\",\n",
    "    \"MAPLE\": \"#ff7f0e\",\n",
    "    \"TPG\": \"#2ca02c\",\n",
    "    \"MATPG\": \"#d62728\",\n",
    "    \"PPO\": \"#9467bd\",\n",
    "    \"SAC\": \"#8c564b\"\n",
    "}\n",
    "\n",
    "# Subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, env_name in enumerate(envs):\n",
    "    ax = axes[idx]\n",
    "    boxplot_data = []\n",
    "\n",
    "    for algo in [\"LGP\", \"MAPLE\", \"TPG\", \"MATPG\", \"PPO\", \"SAC\"]:\n",
    "        vals = df_All_Score[\n",
    "            (df_All_Score[\"algorithm\"] == algo) &\n",
    "            (df_All_Score[\"environment\"] == env_name)\n",
    "        ][\"MaxValidation\"].dropna().tolist()\n",
    "\n",
    "        boxplot_data.append(vals if len(vals) > 0 else [np.nan])\n",
    "\n",
    "    positions = [1, 2, 4, 5, 7, 8]\n",
    "    bplot = ax.boxplot(boxplot_data, positions=positions, labels=labels, vert=True, patch_artist=True, flierprops=dict(marker='o', markersize=8))\n",
    "\n",
    "    # Coloration\n",
    "    for patch, label in zip(bplot['boxes'], labels):\n",
    "        rgba = mcolors.to_rgba(colors[label], alpha=0.3)\n",
    "        patch.set_facecolor(rgba)\n",
    "        patch.set_edgecolor(colors[label])\n",
    "        patch.set_linewidth(3)\n",
    "\n",
    "    for key in ['whiskers', 'caps', 'medians', 'fliers']:\n",
    "        for i, item in enumerate(bplot[key]):\n",
    "            algo_index = i // 2 if key in ['whiskers', 'caps'] else i\n",
    "            algo_label = labels[algo_index]\n",
    "            item.set_color(colors[algo_label])\n",
    "            item.set_linewidth(2 if key != 'medians' else 3)\n",
    "            if key == 'fliers':\n",
    "                item.set_alpha(0.6)\n",
    "\n",
    "    # Separators\n",
    "    ax.axvline(x=3, color=\"black\", linestyle=\"--\", linewidth=2, dashes=(5, 5))\n",
    "    ax.axvline(x=6, color=\"black\", linestyle=\"--\", linewidth=2, dashes=(5, 5))\n",
    "\n",
    "    ax.set_xticks([1.5, 4.5, 7.5])\n",
    "    ax.set_xticklabels(grouped_labels, fontsize=14)\n",
    "\n",
    "    ax.set_title(beautifulEnvName[env_name], fontsize=22, color=\"black\")\n",
    "    ax.spines['bottom'].set_color(\"black\")\n",
    "    ax.spines['left'].set_color(\"black\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(axis='x', labelsize=20, colors=\"black\")\n",
    "    ax.tick_params(axis='y', labelsize=16, colors=\"black\")\n",
    "\n",
    "    if idx % 3 == 0:\n",
    "        ax.set_ylabel(\"Score\", fontsize=22, color=\"black\")\n",
    "\n",
    "# ----------- Custom Legend ----------------\n",
    "legend_ax = fig.add_axes([0.1, -0.055, 0.8, 0.05])\n",
    "simulated_data = [0.9, 0.6, 0, -0.6, -0.9]\n",
    "\n",
    "for i, (label, color) in enumerate(colors.items()):\n",
    "    bplot = legend_ax.boxplot([simulated_data], positions=[i * 1.1 + 0.9], vert=True, patch_artist=True,\n",
    "                              widths=0.3, flierprops=dict(marker='o', markersize=4))\n",
    "\n",
    "    for patch in bplot['boxes']:\n",
    "        patch.set_facecolor(mcolors.to_rgba(color, alpha=0.3))\n",
    "        patch.set_edgecolor(color)\n",
    "        patch.set_linewidth(3)\n",
    "\n",
    "    for key in ['whiskers', 'caps', 'medians', 'fliers']:\n",
    "        for item in bplot[key]:\n",
    "            item.set_color(color)\n",
    "            item.set_linewidth(2 if key != 'medians' else 3)\n",
    "            if key == 'fliers':\n",
    "                item.set_alpha(0.6)\n",
    "\n",
    "    legend_ax.text(i * 1.1 + 1.1, -0.1, label, fontsize=22, va='center', ha='left', color='black')\n",
    "\n",
    "legend_ax.set_xlim(0, len(colors) * 1.2)\n",
    "legend_ax.set_ylim(-1, 1)\n",
    "legend_ax.axis('off')\n",
    "\n",
    "# Layout final\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig('exported_results/comparisonBoxPlot.pdf', format=\"pdf\", dpi=100, transparent=True, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of Mann-Whitney U tests to evaluate is the two propose algorithm, MAPLE and MATPG, are significant\n",
    "\n",
    "Evaluation for MAPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialisation des résultats des tests\n",
    "results = []\n",
    "\n",
    "for e in df_All_Score['environment'].unique():\n",
    "    env_data = df_All_Score[df_All_Score['environment'] == e]\n",
    "    \n",
    "    # Comparaison MAPLE avec tous les autres algorithmes\n",
    "    maple_scores = env_data[env_data['algorithm'] == 'MAPLE']['MaxValidation'].astype(float)\n",
    "    \n",
    "    for other_algo in ['LGP', 'TPG', 'MATPG', 'PPO', 'SAC']:\n",
    "        other_algo_scores = env_data[env_data['algorithm'] == other_algo]['MaxValidation'].astype(float)\n",
    "        \n",
    "        # Vérifiez la taille minimale des distributions\n",
    "        if len(maple_scores) < 2 or len(other_algo_scores) < 2:\n",
    "            print(f\"Skipping test for MAPLE vs {other_algo} in environment {e} due to insufficient data.\")\n",
    "            continue\n",
    "        \n",
    "        # Test de Mann-Whitney\n",
    "        stat, p_value = mannwhitneyu(maple_scores, other_algo_scores, alternative='two-sided')\n",
    "        results.append({\n",
    "            'environment': e,\n",
    "            'algo1': 'MAPLE',\n",
    "            'algo2': other_algo,\n",
    "            'stat': stat,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Ajouter une colonne 'is_significant' qui est True si p-value ajustée < 0.05, sinon False\n",
    "results_df['is_significant'] = results_df['p_value'] < 0.005\n",
    "\n",
    "# Afficher le DataFrame avec la nouvelle colonne\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('mann_whitney_maple.csv', index=False)  # index=False pour ne pas inclure l'index dans le fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation for MATPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des résultats des tests\n",
    "results = []\n",
    "\n",
    "for e in df_All_Score['environment'].unique():\n",
    "    env_data = df_All_Score[df_All_Score['environment'] == e]\n",
    "    \n",
    "    # Comparaison MAPLE avec tous les autres algorithmes\n",
    "    maple_scores = env_data[env_data['algorithm'] == 'MATPG']['MaxValidation'].astype(float)\n",
    "    \n",
    "    for other_algo in ['LGP', 'TPG', 'MAPLE', 'PPO', 'SAC']:\n",
    "        other_algo_scores = env_data[env_data['algorithm'] == other_algo]['MaxValidation'].astype(float)\n",
    "        \n",
    "        # Vérifiez la taille minimale des distributions\n",
    "        if len(maple_scores) < 2 or len(other_algo_scores) < 2:\n",
    "            print(f\"Skipping test for MATPG vs {other_algo} in environment {e} due to insufficient data.\")\n",
    "            continue\n",
    "        \n",
    "        # Test de Mann-Whitney\n",
    "        stat, p_value = mannwhitneyu(maple_scores, other_algo_scores, alternative='two-sided')\n",
    "        results.append({\n",
    "            'environment': e,\n",
    "            'algo1': 'MATPG',\n",
    "            'algo2': other_algo,\n",
    "            'stat': stat,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Ajouter une colonne 'is_significant' qui est True si p-value ajustée < 0.05, sinon False\n",
    "results_df['is_significant'] = results_df['p_value'] < 0.005\n",
    "\n",
    "# Afficher le DataFrame avec la nouvelle colonne\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('mann_whitney_matpg.csv', index=False)  # index=False pour ne pas inclure l'index dans le fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the video, codeGen, data about the best solution\n",
    "\n",
    "For that, we will start by compiling the project (Should already be compiled, but just in case, compile again).\n",
    "\n",
    "Make sure that the gegelati and mujoco library have been installed.\n",
    "\n",
    "\n",
    "\n",
    "The OS used by the notebook and your compiler should be the same too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "main_dir = \"gegelati-apps/mujoco/\"\n",
    "bin_dir = main_dir + \"bin\"\n",
    "\n",
    "def run_command(command, cwd=None, verbose=True):\n",
    "    if(verbose):\n",
    "        print(f\"\\n> Executing: {' '.join(command)}\")\n",
    "\n",
    "    stdout = None if verbose else subprocess.DEVNULL\n",
    "    stderr = None if verbose else subprocess.DEVNULL\n",
    "\n",
    "    result = subprocess.run(command, cwd=cwd, stdout=stdout, stderr=stderr)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Command failed: {' '.join(command)}\")\n",
    "        sys.exit(result.returncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Crée le dossier bin/ s'il n'existe pas\n",
    "if not os.path.exists(bin_dir):\n",
    "    os.makedirs(bin_dir)\n",
    "    print(f\"Created bin directory: {bin_dir}\")\n",
    "\n",
    "# Étape 1 : Générer les fichiers de build avec CMake\n",
    "run_command([\"cmake\", \"..\"], cwd=bin_dir)\n",
    "\n",
    "# Étape 2 : Compiler le projet\n",
    "run_command([\"cmake\", \"--build\", \".\", \"-j\"], cwd=bin_dir)\n",
    "\n",
    "print(\"\\nBuild completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code generation of the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "nbSeed = 10\n",
    "\n",
    "allEnvironments = [\n",
    "    \"inverted_double_pendulum\",\n",
    "    \"hopper\",\n",
    "    \"half_cheetah\",\n",
    "    \"walker2d\",\n",
    "    \"ant\",\n",
    "    \"humanoid\"\n",
    "]\n",
    "\n",
    "algo = [\n",
    "    \"MAPLE\",\n",
    "    \"MATPG\",\n",
    "    \"TPG\"\n",
    "]\n",
    "\n",
    "testSeed = 123456789\n",
    "\n",
    "# Exécution\n",
    "totalNbRuns = len(algo) * len(allEnvironments) * nbSeed\n",
    "nbRunned = 0\n",
    "\n",
    "for a in algo:\n",
    "    for e in allEnvironments:\n",
    "        for i in range(nbSeed):\n",
    "\n",
    "            print(f\"Running {nbRunned + 1}/{totalNbRuns}: {a} - {e} - seed {i}\", end='\\r')\n",
    "\n",
    "            cmd = [\n",
    "                \"./bin/Release/renderMujoco\",\n",
    "                \"-d\", f\"../../logs/{a}/{e}/out_best.{i}.p0.{e}.dot\",\n",
    "                \"-p\", f\"../../logs/{a}/{e}/exported_params.{e}.p0.json\",\n",
    "                \"-c\", \"1\",\n",
    "                \"-v\", \"2\",\n",
    "                \"-u\", f\"{e}\",\n",
    "                \"-s\", f\"{testSeed}\",\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                run_command(cmd, cwd=main_dir, verbose=False)\n",
    "            except RuntimeError as err:\n",
    "                print(f\"\\n{err}\")\n",
    "                print(f\"Error with algo={a}, env={e}, seed={i}\")\n",
    "\n",
    "            nbRunned += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate video result for each test\n",
    "\n",
    "It takes a loot of time, you should reduce to generate only some behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbSeed = 10\n",
    "\n",
    "allEnvironments = [\n",
    "    \"inverted_double_pendulum\",\n",
    "    \"hopper\",\n",
    "    \"half_cheetah\",\n",
    "    \"walker2d\",\n",
    "    \"ant\",\n",
    "    \"humanoid\"\n",
    "]\n",
    "\n",
    "algo = [\n",
    "    \"MAPLE\",\n",
    "    \"MATPG\",\n",
    "    \"TPG\"\n",
    "]\n",
    "\n",
    "testSeed = 123456789\n",
    "\n",
    "# Exécution\n",
    "totalNbRuns = len(algo) * len(allEnvironments) * nbSeed\n",
    "nbRunned = 0\n",
    "\n",
    "run_command([\"./scripts/scriptServerMujoco.sh\"], cwd=main_dir)\n",
    "\n",
    "os.environ[\"DISPLAY\"] = \":0\"\n",
    "\n",
    "for a in algo:\n",
    "    for e in allEnvironments:\n",
    "        for i in range(nbSeed):\n",
    "\n",
    "            print(f\"Running {nbRunned + 1}/{totalNbRuns}: {a} - {e} - seed {i}\", end='\\r')\n",
    "\n",
    "            cmd = [\n",
    "                \"./bin/Release/renderMujoco\",\n",
    "                \"-d\", f\"../../logs/{a}/{e}/out_best.{i}.p0.{e}.dot\",\n",
    "                \"-p\", f\"../../logs/{a}/{e}/exported_params.{e}.p0.json\",\n",
    "                \"-f\", \"1\",\n",
    "                \"-g\", \"../../videoResults/\",\n",
    "                \"-u\", f\"{e}\",\n",
    "                \"-s\", f\"{testSeed}\",\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                run_command(cmd, cwd=main_dir, verbose=True)\n",
    "            except RuntimeError as err:\n",
    "                print(f\"\\n{err}\")\n",
    "                print(f\"Error with algo={a}, env={e}, seed={i}\")\n",
    "\n",
    "            nbRunned += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print behavior of an agent\n",
    "\n",
    "Select an agent by selecting\n",
    " - Algorithm\n",
    " - Environment\n",
    " - Seed\n",
    "\n",
    "The script will run this agent for 20 episodes, will save the state and action values and print the correlation information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbEpisode = 20\n",
    "\n",
    "selectedSeed = 5\n",
    "env = \"ant\"\n",
    "algo = \"MAPLE\"\n",
    "\n",
    "testSeed = 123456789\n",
    "\n",
    "for i in range(nbEpisode):\n",
    "\n",
    "    print(f\"Running {i + 1}/{nbEpisode}: {a} - {e} - seed {i}\", end='\\r')\n",
    "\n",
    "\n",
    "    cmd = [\n",
    "        \"./bin/Release/renderMujoco\",\n",
    "        \"-d\", f\"../../logs/{algo}/{env}/out_best.{selectedSeed}.p0.{env}.dot\",\n",
    "        \"-p\", f\"../../logs/{algo}/{env}/exported_params.{env}.p0.json\",\n",
    "        \"-v\", \"2\",\n",
    "        \"-u\", f\"{env}\",\n",
    "        \"-s\", f\"{testSeed + i}\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        run_command(cmd, cwd=main_dir, verbose=False)\n",
    "    except RuntimeError as err:\n",
    "        print(f\"\\n{err}\")\n",
    "        print(f\"Error with algo={a}, env={e}, seed={i}\")\n",
    "\n",
    "    nbRunned += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load state and action csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the usage of sensors by each actions (would be complex to do automaticaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the correlations between states and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
